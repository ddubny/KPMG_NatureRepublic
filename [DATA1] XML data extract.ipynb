{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re, html\n",
    "from bs4 import BeautifulSoup as BS, NavigableString, SoupStrainer\n",
    "from html_table_parser import parser_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "if not hasattr(collections, 'Callable'):\n",
    "    collections.Callable = collections.abc.Callable\n",
    "\n",
    "parser_d0350 = SoupStrainer(\"section-2\")\n",
    "section2_pattern = re.compile(r\"<SECTION-2((?!<SECTION-2)[\\S\\s\\n])*?(D-0-3-5-0)[\\S\\s\\n]*?</SECTION-2>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일시스템에서 xml 문서들을 불러오기 \n",
    "\n",
    "import os\n",
    "\n",
    "path = 'C:/Users/Samsung/Documents/KPMG/kic/'\n",
    "file_list = os.listdir(path)\n",
    "file_list_py = [file for file in file_list if file.endswith('.xml')] \n",
    "\n",
    "path_line = []\n",
    "for i in file_list_py:\n",
    "\n",
    "    path= 'C:/Users/Samsung/Documents/KPMG/kic/'+ i\n",
    "    path_line.append(path)\n",
    "\n",
    "#print(path_line) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 텍스트 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base = pd.DataFrame(columns=['full_text'])\n",
    "\n",
    "for i in range(len(path_line)):\n",
    "    # 인코딩 방식이 다른 문헌의 경우 예외를 적용하도록 함.\n",
    "    try : \n",
    "        with open(path_line[i], 'r', encoding=\"cp949\") as data_xml:\n",
    "            dsd_xml = data_xml.read()\n",
    "            dsd_xml = dsd_xml.replace('&cr;', '&#13;')\n",
    "            dsd_xml = re.sub('(\\n|\\r)?</*SPAN.*?>(\\n|\\r)?', '', dsd_xml)\n",
    "            dsd_xml = html.unescape(dsd_xml)\n",
    "            section2_section = section2_pattern.search(dsd_xml)\n",
    "            section2_section = section2_section.group()\n",
    "        remark_page=BS(section2_section, 'lxml', parse_only=parser_d0350).find(\"section-2\")\n",
    "    except:\n",
    "        with open(path_line[i], 'r', encoding=\"utf-8\",errors='ignore') as data_xml:\n",
    "            dsd_xml = data_xml.read()\n",
    "            dsd_xml = dsd_xml.replace('&cr;', '&#13;')\n",
    "            dsd_xml = re.sub('(\\n|\\r)?</*SPAN.*?>(\\n|\\r)?', '', dsd_xml)\n",
    "            dsd_xml = html.unescape(dsd_xml)\n",
    "            section2_section = section2_pattern.search(dsd_xml)\n",
    "            section2_section = section2_section.group()\n",
    "        remark_page=BS(section2_section, 'lxml', parse_only=parser_d0350).find(\"section-2\")\n",
    "\n",
    "    # xml 문서에서 텍스트 형태로 변환하기  \n",
    "    txt_line = [list(text.stripped_strings) for text in remark_page.find_all(recursive=False) if list(text.stripped_strings) != [] and 'border=\"1\"' not in text.prettify()]\n",
    "    raw_txt = sum(txt_line, [])\n",
    "    txt = \"\\n\".join(raw_txt)\n",
    "    df_base = df_base.append(pd.DataFrame([txt], columns=['full_text']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_report = df_base.reset_index(inplace=False).drop(columns=['index'])\n",
    "base_report.to_csv(\"base_report(\\n).csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 테이블 확인 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 표 확인\n",
    "table1 = remark_page.find('table', border=1)\n",
    "pd.DataFrame(parser_functions.make2d(table1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open( 'C:/Users/Samsung/Documents/KPMG/kic/20210510000378.xml', 'r', encoding=\"cp949\", errors='ignore') as data_xml:\n",
    "    dsd_xml = data_xml.read()\n",
    "    dsd_xml = dsd_xml.replace('&cr;', '&#13;')\n",
    "    dsd_xml = re.sub('(\\n|\\r)?</*SPAN.*?>(\\n|\\r)?', '', dsd_xml)\n",
    "    dsd_xml = html.unescape(dsd_xml)\n",
    "    section2_section = section2_pattern.search(dsd_xml)\n",
    "    section2_section = section2_section.group()\n",
    "    \n",
    "remark_page=BS(section2_section, 'lxml', parse_only=parser_d0350).find(\"section-2\")\n",
    "\n",
    "[pd.DataFrame(parser_functions.make2d(table)) for table in remark_page.find_all('table', border=1, recursive=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_table = pd.DataFrame(columns=['full_text'])\n",
    "\n",
    "for i in range(len(path_line)):\n",
    "    # 인코딩 방식이 다른 문헌의 경우 예외를 적용하도록 함.\n",
    "    try : \n",
    "        with open(path_line[i], 'r', encoding=\"cp949\") as data_xml:\n",
    "            dsd_xml = data_xml.read()\n",
    "            dsd_xml = dsd_xml.replace('&cr;', '&#13;')\n",
    "            dsd_xml = re.sub('(\\n|\\r)?</*SPAN.*?>(\\n|\\r)?', '', dsd_xml)\n",
    "            dsd_xml = html.unescape(dsd_xml)\n",
    "            section2_section = section2_pattern.search(dsd_xml)\n",
    "            section2_section = section2_section.group()\n",
    "        remark_page=BS(section2_section, 'lxml', parse_only=parser_d0350).find(\"section-2\")\n",
    "    except:\n",
    "        with open(path_line[i], 'r', encoding=\"utf-8\",errors='ignore') as data_xml:\n",
    "            dsd_xml = data_xml.read()\n",
    "            dsd_xml = dsd_xml.replace('&cr;', '&#13;')\n",
    "            dsd_xml = re.sub('(\\n|\\r)?</*SPAN.*?>(\\n|\\r)?', '', dsd_xml)\n",
    "            dsd_xml = html.unescape(dsd_xml)\n",
    "            section2_section = section2_pattern.search(dsd_xml)\n",
    "            section2_section = section2_section.group()\n",
    "        remark_page=BS(section2_section, 'lxml', parse_only=parser_d0350).find(\"section-2\")\n",
    "\n",
    "    # xml 문서에서 표로 변환하기  \n",
    "    table_line = [pd.DataFrame(parser_functions.make2d(table)) for table in remark_page.find_all('table', border=1,recursive=False)]\n",
    "    raw_txt = sum( txt_line, [])\n",
    "    txt = \"   \".join(raw_txt)\n",
    "    df_base = df_base.append(pd.DataFrame([txt], columns=['full_text']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#텍스트와 표를 동시 추출하는 방법 \n",
    "\n",
    "df_textwithtable = pd.DataFrame(columns=['full_text'])\n",
    "\n",
    "for i in range(1):\n",
    "\n",
    "    # 인코딩 방식이 다른 문헌의 경우 예외를 적용하도록 함.\n",
    "    try : \n",
    "        with open(path_line[i], 'r', encoding=\"cp949\") as data_xml:\n",
    "            dsd_xml = data_xml.read()\n",
    "            dsd_xml = dsd_xml.replace('&cr;', '&#13;')\n",
    "            dsd_xml = re.sub('(\\n|\\r)?</*SPAN.*?>(\\n|\\r)?', '', dsd_xml)\n",
    "            dsd_xml = html.unescape(dsd_xml)\n",
    "            section2_section = section2_pattern.search(dsd_xml)\n",
    "            section2_section = section2_section.group()\n",
    "        remark_page=BS(section2_section, 'lxml', parse_only=parser_d0350).find(\"section-2\")\n",
    "    except:\n",
    "        with open(path_line[i], 'r', encoding=\"utf-8\",errors='ignore') as data_xml:\n",
    "            dsd_xml = data_xml.read()\n",
    "            dsd_xml = dsd_xml.replace('&cr;', '&#13;')\n",
    "            dsd_xml = re.sub('(\\n|\\r)?</*SPAN.*?>(\\n|\\r)?', '', dsd_xml)\n",
    "            dsd_xml = html.unescape(dsd_xml)\n",
    "            section2_section = section2_pattern.search(dsd_xml)\n",
    "            section2_section = section2_section.group()\n",
    "        remark_page=BS(section2_section, 'lxml', parse_only=parser_d0350).find(\"section-2\")\n",
    "    \n",
    "    # 텍스트와 표를 동시 추출하기 \n",
    "    # [list(text.stripped_strings) for text in remark_page.find_all(recursive=False) if list(text.stripped_strings) != [] and 'border=\"1\"' not in text.prettify()]\n",
    "    # [pd.DataFrame(parser_functions.make2d(table)) for table in remark_page.find_all('table', border=1,recursive=False)]\n",
    "    \n",
    "    doc = []\n",
    "    for text, table in zip( remark_page.find_all(recursive=False),remark_page.find_all('table', border=1,recursive=False)) :\n",
    "        \n",
    "        if list(text.stripped_strings) != [] and 'border=\"1\"'not in text.prettify():\n",
    "            txt_line = list(text.stripped_strings)\n",
    "            doc.extend(txt_line)\n",
    "        \n",
    "        table_line = [pd.DataFrame(parser_functions.make2d(table))]\n",
    "        doc.extend(table_line)\n",
    "        \n",
    "    #raw_txt = sum(doc, [])\n",
    "    \n",
    "    os.chdir(\"c:/Users/Samsung/Documents/KPMG/info_file\")\n",
    "    with open(str(i) + '재무제표 파일.csv', 'w', newline='\\n') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(doc)   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jbnu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ab99aeb74e800cddeddd90cbec21ff2756abb5b97b4b71bf3a1dcdf227ca9b5a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
